#!/usr/bin/env python 
import numpy as np
from pathlib import Path
import hdf5maker as h5m
import hdf5plugin
import h5py
import multiprocessing as mp
import time
from argparse import ArgumentParser

def convert_data_file(fname_in, fname_out, start, stop):
    """
    Wrapper to read one data file and convert to hdf5
    """
    t0 = time.time()
    raw = h5m.EigerRawFileReader(fname_in)
    raw.seek(start)
    data = raw.read(stop-start)
    t1 = time.time()
    h5m.write_data_file(fname_out, data, image_nr_low=start+1)
    t2 = time.time()
    return {'reading':t1-t0, 'writing':t2-t1}


if __name__ == "__main__":
    t_start = time.time()

    #Parse input arguments
    parser = ArgumentParser()
    parser.add_argument("input", help="Master file of input data", type = Path)
    parser.add_argument("output", help="Master file of output data", type = Path)
    parser.add_argument("-j", "--num_threads", help="Number of threads used for processing", type = int, default=4)
    parser.add_argument("-v", "--verbose", help="Verbose output", action="store_true")
    parser.add_argument("-s", "--sample", help="Only convert the first 100 frames", action="store_true")
    args = parser.parse_args()

    fname_in = args.input
    fname_out = args.output

    # Open the raw file to find out how much data we have
    raw = h5m.EigerRawFileReader(fname_in)
    num_data_files = len(raw.frames_per_file)
    start = np.zeros(num_data_files+1, dtype=np.int64)
    start[1:] = np.cumsum(raw.frames_per_file)
    frames_to_read = list(zip(start, start[1:]))
    print(frames_to_read)
    raw.close()

    # Mask for defective pixels, as a default contains only module gaps
    pixel_mask = raw.module_gaps

    # Generate filenames for data out files
    fname_out_data = [fname_out.parent/f'test_data_{i:06d}.h5' for i in range(num_data_files)]
    if args.sample:
        fname_out_data = fname_out_data[0:1]
        frames_to_read[0] = (0,100)
    
    conversion_args = [(fname_in, fname, start, stop) for (start, stop),fname in zip(frames_to_read, fname_out_data)]
    pool = mp.Pool(args.num_threads)
    result = pool.starmap(convert_data_file, conversion_args)

    # Write hdf5 master file
    h5m.write_master_file(fname_out, fname_out_data, pixel_mask=pixel_mask)
    t_stop = time.time()

    print(f'Conversion took: {t_stop-t_start:.2f}s')

    r = max(r['reading'] for r in result)
    w = max(r['writing'] for r in result)
    print(f'{r=}, {w=}, {r+w}')