#!/usr/bin/env python 
import os
import numpy as np
from pathlib import Path
import hdf5maker as h5m
import hdf5plugin
import h5py
import multiprocessing as mp
import time
from argparse import ArgumentParser

def convert_data_file(fname_in, fname_out, start, stop):
    """
    Wrapper to read one data file and convert to hdf5
    """
    t0 = time.time()
    raw = h5m.RawFile(fname_in)
    raw.seek(start)
    data = raw.read(stop-start)
    t1 = time.time()
    h5m.write_data_file(fname_out, data, image_nr_low=start+1)
    t2 = time.time()
    return {'reading':t1-t0, 'writing':t2-t1}


if __name__ == "__main__":
    t_start = time.time()

    #Parse input arguments
    parser = ArgumentParser()
    parser.add_argument("input", help="Master file of input data", type = Path)
    parser.add_argument("path_out", help="Output path for hdf5 files", type = Path)
    parser.add_argument("-j", "--num_threads", help="Number of threads used for processing", type = int, default=4)
    parser.add_argument("-n", "--custom_name", help="Custom name for the output file",  default=None)
    parser.add_argument("-b", "--bad_pixels", help="List of bad pixels in row, col format",  default=None)
    parser.add_argument("-s", "--sample", help="Only convert the first 100 frames", action="store_true")
    args = parser.parse_args()

    fname_in = args.input
    args.path_out.mkdir(exist_ok = True)
    fname_out = h5m.get_output_fname(fname_in, args.path_out, args.custom_name)

    # Open the raw file to find out how much data we have
    print(f'Reading: {fname_in}')
    raw = h5m.RawFile(fname_in)
    num_data_files = len(raw.frames_per_file)
    start = np.zeros(num_data_files+1, dtype=np.int64)
    start[1:] = np.cumsum(raw.frames_per_file)
    frames_to_read = list(zip(start, start[1:]))
    raw.close()

    print(f'Image size: {raw.image_size}')
    print(f'Dynamic range: {raw.dr}')
    print(f'Total frames: {raw.total_frames}')

    # Mask for defective pixels, as a default contains only module gaps
    pixel_mask = raw.module_gaps

    #Look for additional pixels to mask 
    try:
        if args.bad_pixels is None:
            fname_bp = Path('bad_pixels.txt')
        else: 
            fname_bp = args.bad_pixels
        pixels = h5m.read_bad_pixels(fname_bp)
        print(f'Loading pixels to mask from: {fname_bp}')
        for p in pixels:
            pixel_mask[p] = True
    except:
        print(f'No bad pixels file found')


    # Generate filenames for data out files
    fname_out_data = [fname_out.parent/f'{fname_out.stem}_{i:06d}.h5' for i in range(num_data_files)]
    if args.sample:
        fname_out_data = fname_out_data[0:1]
        n_frames = (100, raw.total_frames)[raw.total_frames<100]
        frames_to_read = [(0,n_frames)]
        print(f'Option -s used, converting {frames_to_read}')
    
    # Run conversion in parallel
    conversion_args = [(fname_in, fname, start, stop) for (start, stop),fname in zip(frames_to_read, fname_out_data)]
    pool = mp.Pool(args.num_threads)
    result = pool.starmap(convert_data_file, conversion_args)
    

    # Write hdf5 master file
    h5m.write_master_file(fname_out, fname_out_data, pixel_mask=pixel_mask)
    t_stop = time.time()

    print(f'Processing took: {t_stop-t_start:.2f}s for {frames_to_read[-1][1]} frames')